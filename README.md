# ğŸ“ Educational Content Assistant

<p align="center">
  <img src="https://readme-typing-svg.demolab.com?font=Fira+Code&size=28&pause=1000&color=38BDF8&center=true&vCenter=true&width=900&lines=AI-powered+Learning+Assistant;Ask+Questions+%7C+Practice+%7C+Quiz;ScaleDown+Compression+%7C+Groq+LLMs" />
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Status-Active-success" />
  <img src="https://img.shields.io/badge/AI-Groq-orange" />
  <img src="https://img.shields.io/badge/Compression-ScaleDown-blue" />
</p>

---

## âœ¨ What is Educational Content Assistant?

**Educational Content Assistant** is an AIâ€‘powered learning platform that lets students:

- ğŸ“– Load textbooks
- ğŸ’¬ Ask naturalâ€‘language questions
- ğŸ§  Get contextâ€‘aware AI answers
- ğŸ“ Generate practice questions
- ğŸ¯ Attempt MCQ quizzes with live accuracy tracking

All while **reducing textbook size by ~70% using ScaleDown compression** âš¡

---

## ğŸš€ Unique Selling Points (USP)

### ğŸ—œï¸ ScaleDown Compression (70% reduction)
- Textbooks are **compressed semantically**, not truncated
- Preserves learning value while drastically reducing token usage
- Faster responses + lower LLM cost

> ğŸ“‰ Result: Smaller context â†’ faster Groq inference â†’ smoother UX

---

### âš¡ Groqâ€‘Powered LLM Inference
- Ultraâ€‘fast responses using **Groq API**
- Used for:
  - Answering questions
  - Generating practice problems
  - Creating MCQ quizzes

> â±ï¸ Nearâ€‘instant answers even on large books

---

### ğŸ§© Contextâ€‘Aware Retrieval
- Book is chunked and stored
- Relevant sections are randomly sampled
- Prevents hallucination by **answering strictly from book context**

---

## ğŸ§  Features

### â“ Ask Questions
- Ask anything from the book
- AI answers strictly from textbook context

### ğŸ“ Practice Mode
- Generates 5 conceptual questions
- Great for revision

### ğŸ¯ Quiz Mode
- 5 MCQs per quiz
- Individual submission per question
- Accuracy & progress tracking

---

## ğŸ› ï¸ Tech Stack

### Backend
<p>
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg" height="40" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/fastapi/fastapi-original.svg" height="40" />
</p>

### Frontend
<p>
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/react/react-original.svg" height="40" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/javascript/javascript-original.svg" height="40" />
  <img src="https://cdn.jsdelivr.net/gh/devicons/devicon/icons/css3/css3-original.svg" height="40" />
</p>

### AI & Infra
<p>
  <img src="https://assets-global.website-files.com/64f8f8cbe8c9d58c3f20a5f4/64f8fa1c3f2f7e6d91b1b3aa_groq-logo.svg" height="40" />
  <img src="https://img.shields.io/badge/ScaleDown-Compression-blue" />
</p>

---

## ğŸ“ Project Structure

```
backend/
 â”œâ”€â”€ main.py        # FastAPI server
 â”œâ”€â”€ llm.py         # Groq LLM integration
 â”œâ”€â”€ scaledown.py   # 70% compression logic
 â”œâ”€â”€ chunking.py    # Text chunking
 â”œâ”€â”€ retrieval.py   # Context retrieval
 â”œâ”€â”€ store.py       # Chunk storage
 â””â”€â”€ books.py       # Book loader

frontend/
 â””â”€â”€ src/
     â”œâ”€â”€ App.jsx
     â”œâ”€â”€ api.js
     â””â”€â”€ App.css
```

---

## âš™ï¸ Running Locally

### Backend
```bash
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```

### Frontend
```bash
cd frontend
npm install
npm run dev
```

---

## ğŸ“ˆ Why This Project Matters

- Reduces AI cost using compression
- Improves learning efficiency
- Shows realâ€‘world AI system design
- Combines **ML + Backend + Frontend**

Perfect for:
- ğŸ§‘â€ğŸ“ Students
- ğŸ‘¨â€ğŸ’» AI Engineers
- ğŸ“š EdTech platforms

---

<p align="center">
  <img src="https://readme-typing-svg.demolab.com?font=Fira+Code&pause=1000&color=22C55E&center=true&vCenter=true&width=700&lines=Learn+Smarter.;Ask+Better.;Scale+Efficiently." />
</p>

